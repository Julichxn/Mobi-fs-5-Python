{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Bonus Tasks](svm_segm.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "import skimage.morphology as morph\n",
    "import skimage.util\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_result(img, seg, border_radius=1, interior_opacity=1, interior_opacity_decay=0.9, color=(0,1,0)):\n",
    "    img  = np.dstack([img] * 3).copy()\n",
    "    img -= img.min()\n",
    "    img /= img.max()\n",
    "    selem  = morph.disk(border_radius)\n",
    "    seg_bd = np.logical_xor(morph.binary_dilation(seg, selem), morph.binary_erosion(seg, selem))\n",
    "    mask_decay = ndi.distance_transform_edt(seg)\n",
    "    for i in range(3):\n",
    "        opacity = interior_opacity / pow(1 + mask_decay[seg], interior_opacity_decay)\n",
    "        img[:,:,i][seg] = color[i] * opacity + (1 - opacity) * img[:,:,i][seg]\n",
    "        img[:,:,i][seg_bd] = color[i]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sizes = (32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**[Task 1.1.]()** Implement `create_data_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_matrix(img) :\n",
    "    patch = skimage.util.view_as_blocks(img, block_shape = patch_sizes)\n",
    "    num_patch = patch.shape[0] * patch.shape[1]\n",
    "    X = patch.reshape(num_patch, -1)\n",
    "    \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.2.]()** Implement `create_gt_labels_vector`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_labels_vector(img) :\n",
    "    patch = skimage.util.view_as_blocks(img, block_shape = patch_sizes)\n",
    "    \n",
    "    rows, cols = patch.shape[:2]\n",
    "    labels = np.empty(rows * cols, dtype = int)\n",
    "    \n",
    "\n",
    "    a = 0\n",
    "\n",
    "    for i in range(rows) :\n",
    "        for j in range(cols) :\n",
    "            patches = patch[i, j]\n",
    "\n",
    "            if np.mean(patches) > 0.5 :\n",
    "                labels[a] = 1\n",
    "            \n",
    "            elif np.mean(patches) == 0 :\n",
    "                labels[a] = -1\n",
    "            \n",
    "            else :\n",
    "                labels[a] = 0\n",
    "\n",
    "            a += 1\n",
    "\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.3.]()** Create the SVM classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(class_weight='balanced', gamma=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.3 (a).]()** Create the data matrices for the images `dna-33` and `dna-44`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1344, 1024)\n"
     ]
    }
   ],
   "source": [
    "dna33 = plt.imread('data/NIH3T3/im/dna-33.png')\n",
    "dna44 = plt.imread('data/NIH3T3/im/dna-44.png')\n",
    "\n",
    "a3 = create_data_matrix(dna33)\n",
    "a4 = create_data_matrix(dna44)\n",
    "\n",
    "a3.dtype\n",
    "print(a3.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.3 (b).]()** Create the corresponding ground truth label vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ...  0 -1 -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "g3 = plt.imread('data/NIH3T3/gt/33.png')\n",
    "g4 = plt.imread('data/NIH3T3/gt/44.png')\n",
    "\n",
    "b3 = create_gt_labels_vector(g3)\n",
    "b4 = create_gt_labels_vector(g4)\n",
    "\n",
    "print(b3)\n",
    "b3.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.3 (c).]()** Create the *combined* data matrices and ground truth label vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2109, 1024)\n",
      "(2109,)\n"
     ]
    }
   ],
   "source": [
    "a_valid = np.concatenate([a3[(b3 == 1) | (b3 == -1)], a4[(b4 == 1) | (b4 == -1)]])\n",
    "b_valid = np.concatenate([b3[(b3 == 1) | (b3 == -1)], b4[(b4 == 1) | (b4 == -1)]])\n",
    "print(a_valid.shape)\n",
    "print(b_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.3 (d).]()** Train the classifier using the data matrix and label vectors from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clef = clf.fit(a_valid, b_valid) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.4.]()** Implement the function `predict_image`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img) :\n",
    "\n",
    "    X = create_data_matrix(img)\n",
    "    prediction = clf.predict(X)\n",
    "    result_falses = np.zeros(img.shape, dtype=bool)\n",
    "    \n",
    "    # view from the result in windows (if changed here, also changed in results)\n",
    "    patch_height, patch_width = patch_sizes\n",
    "    step = patch_width // 2\n",
    "    patches = skimage.util.view_as_windows(result_falses, window_shape = patch_sizes, step = step)\n",
    "    t = np.full(patch_sizes, True, dtype=bool)\n",
    "\n",
    "    for i in range(rows) :\n",
    "        for n in range(cols) :\n",
    "            # convert the patch index into the corresponding labels index in the vector\n",
    "            num = i * patches.shape[1] + n\n",
    "            # if the label in the prediction is 1, change the patch to all True\n",
    "            if prediction[num] == 1 :       \n",
    "                patches[i, n] = t\n",
    "    \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m img = plt.imread(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata/NIH3T3/im/dna-0.png\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m seg = \u001b[43mpredict_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(seg)\n\u001b[32m      6\u001b[39m plt.imshow(seg, vmin=\u001b[32m0\u001b[39m, vmax=\u001b[32m1\u001b[39m, cmap=\u001b[33m'\u001b[39m\u001b[33mgray\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mpredict_image\u001b[39m\u001b[34m(img)\u001b[39m\n\u001b[32m     10\u001b[39m patches = skimage.util.view_as_windows(result_falses, window_shape = patch_sizes, step = step)\n\u001b[32m     11\u001b[39m t = np.full(patch_sizes, \u001b[38;5;28;01mTrue\u001b[39;00m, dtype=\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mrows\u001b[49m) :\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cols) :\n\u001b[32m     15\u001b[39m         \u001b[38;5;66;03m# convert the patch index into the corresponding labels index in the vector\u001b[39;00m\n\u001b[32m     16\u001b[39m         num = i * patches.shape[\u001b[32m1\u001b[39m] + n\n",
      "\u001b[31mNameError\u001b[39m: name 'rows' is not defined"
     ]
    }
   ],
   "source": [
    "img = plt.imread(f'data/NIH3T3/im/dna-0.png')\n",
    "seg = predict_image(img)\n",
    "\n",
    "print(seg)\n",
    "\n",
    "plt.imshow(seg, vmin=0, vmax=1, cmap='gray')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(blend_result(img, seg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task 1.5.]()** Perform batch processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m ground = plt.imread(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata/NIH3T3/gt/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m binground = ground > \u001b[32m0.5\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m binimg = \u001b[43mpredict_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m dice = \u001b[32m2\u001b[39m * (binimg * binground).sum() / (binimg.sum() + binground.sum())\n\u001b[32m     14\u001b[39m \u001b[38;5;28mall\u001b[39m.append(dice)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mpredict_image\u001b[39m\u001b[34m(img)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_image\u001b[39m(img) :\n\u001b[32m      3\u001b[39m     X = create_data_matrix(img)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     prediction = \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     result_falses = np.zeros(img.shape, dtype=\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# view from the result in windows (if changed here, also changed in results)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/sklearn/pipeline.py:600\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[32m    599\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m         Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m].predict(Xt, **params)\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:1042\u001b[39m, in \u001b[36mStandardScaler.transform\u001b[39m\u001b[34m(self, X, copy)\u001b[39m\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, copy=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1028\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[32m   1029\u001b[39m \n\u001b[32m   1030\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1040\u001b[39m \u001b[33;03m        Transformed array.\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1042\u001b[39m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     copy = copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy\n\u001b[32m   1045\u001b[39m     X = \u001b[38;5;28mself\u001b[39m._validate_data(\n\u001b[32m   1046\u001b[39m         X,\n\u001b[32m   1047\u001b[39m         reset=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1052\u001b[39m         force_all_finite=\u001b[33m\"\u001b[39m\u001b[33mallow-nan\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1053\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/sklearn/utils/validation.py:1661\u001b[39m, in \u001b[36mcheck_is_fitted\u001b[39m\u001b[34m(estimator, attributes, msg, all_or_any)\u001b[39m\n\u001b[32m   1658\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is not an estimator instance.\u001b[39m\u001b[33m\"\u001b[39m % (estimator))\n\u001b[32m   1660\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg % {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator).\u001b[34m__name__\u001b[39m})\n",
      "\u001b[31mNotFittedError\u001b[39m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "seq = [28, 29, 33, 44, 46, 49]\n",
    "\n",
    "all = []\n",
    "\n",
    "for i in seq :\n",
    "    img = plt.imread(f'data/NIH3T3/im/dna-{i}.png')\n",
    "    ground = plt.imread(f'data/NIH3T3/gt/{i}.png')\n",
    "\n",
    "    binground = ground > 0.5\n",
    "    binimg = predict_image(img)\n",
    "    \n",
    "    dice = 2 * (binimg * binground).sum() / (binimg.sum() + binground.sum())\n",
    "\n",
    "    all.append(dice)\n",
    "\n",
    "    print('image: ' + str(i) + ', Dice: ' + str(round(dice, 2)))\n",
    "\n",
    "print()\n",
    "print('Average Dice: ' + str(round(sum(all)/len(all), 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
